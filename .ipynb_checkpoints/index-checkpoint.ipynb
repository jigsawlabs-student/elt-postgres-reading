{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "whole-decimal",
   "metadata": {},
   "source": [
    "# ETL in Postgres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cellular-investigator",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fiscal-waters",
   "metadata": {},
   "source": [
    "In the previous lesson, we saw the benefits of moving over to the star schema.  With the star schema, while we lose having our data in third normal form, we benefit from less complex queries and speedier queries.\n",
    "\n",
    "Our data will start in an OLTP database, and then as data engineers, we'll copy this data over to an OLAP database for data analysis.  But what are the commands to actually accomplish this?  \n",
    "\n",
    "We'll work through this in this lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "german-pharmacology",
   "metadata": {},
   "source": [
    "### Working with Customers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "successful-evanescence",
   "metadata": {},
   "source": [
    "Now thinking of our movie rentals schema again, our data will start in a database in an OLTP schema, like the one below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metric-cooperative",
   "metadata": {},
   "source": [
    "> <img src=\"./pagila_schema.png\" width=\"85%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-talent",
   "metadata": {},
   "source": [
    "And we'll need to move it to the star schema as we see below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quick-runner",
   "metadata": {},
   "source": [
    "<img src=\"./star_schemad_movies.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clear-loading",
   "metadata": {},
   "source": [
    "So let's just focus in on the migrating the customer information.  We'll want to end with a customer table that fits into our star schema and has the columns we see in the diagram below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessory-salon",
   "metadata": {},
   "source": [
    "<img src=\"./customers_table.png\" width=\"20%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-gross",
   "metadata": {},
   "source": [
    "Now remember that as we're starting with our OLTP schema, the columns of customer name, the address, city, and zipcode are spread across multiple tables. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frank-notification",
   "metadata": {},
   "source": [
    "> <img src=\"./customer_pg.png\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greenhouse-envelope",
   "metadata": {},
   "source": [
    "So just to fill the information for customer in the OLAP schema, we'll need to extract information from the customer, city, and address tables in our OLTP schema.  Let's get to it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equal-thursday",
   "metadata": {},
   "source": [
    "### Creating the customer table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satellite-research",
   "metadata": {},
   "source": [
    "As a first step, we can create the customer table, which we name `olapCustomer`, like so.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-commercial",
   "metadata": {},
   "source": [
    "```SQL\n",
    "CREATE TABLE olapCustomer\n",
    "(\n",
    "  id SERIAL PRIMARY KEY,\n",
    "  customer_id  smallint NOT NULL,\n",
    "  first_name   varchar(45) NOT NULL,\n",
    "  last_name    varchar(45) NOT NULL,\n",
    "  address      varchar(50) NOT NULL,\n",
    "  zipcode  varchar(50),\n",
    "  city         varchar(50) NOT NULL\n",
    ");\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binding-lodging",
   "metadata": {},
   "source": [
    "So this first step is pretty straight forward: we create a table named `olapCustomer` that has columns of the `customer_id`, first and last name, and `address`, `zipcode`, and `city`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handled-closing",
   "metadata": {},
   "source": [
    "The next step is to take the data from our customer, address, and city tables, and copy it into the `olapCustomer` table.  \n",
    "\n",
    "Before we copy over the data, let's just practice selecting the data needed from the various tables.  We'll do this below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dangerous-debut",
   "metadata": {},
   "source": [
    "> <img src=\"./select_trunc.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-format",
   "metadata": {},
   "source": [
    "So we have our select statement, with the properly joined tables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efficient-instrument",
   "metadata": {},
   "source": [
    "And then to select this data and insert it into the corresponding table, we simply place an `INSERT INTO` on top of the select statement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleasant-henry",
   "metadata": {},
   "source": [
    "```sql\n",
    "INSERT INTO olapCustomer (id, customer_id, first_name, last_name, address, zipcode, city)\n",
    "SELECT customer.customer_id,\n",
    "       customer.customer_id,\n",
    "       customer.first_name,\n",
    "       customer.last_name,\n",
    "       address.address,\n",
    "       city.city,\n",
    "       address.postal_code\n",
    "FROM customer\n",
    "JOIN address ON (customer.address_id = address.address_id)\n",
    "JOIN city    ON (address.city_id = city.city_id);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleared-bidder",
   "metadata": {},
   "source": [
    "So this extraction is really: \n",
    "1. A `SELECT` statement, with all of the corresponding joins.  \n",
    "2. Preceded by an `INSERT INTO` statement with the name of the table and corresponding columns to fill."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "awful-sussex",
   "metadata": {},
   "source": [
    "### Creating a date table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "norwegian-relation",
   "metadata": {},
   "source": [
    "Now it's worth seeing how the date dimension table is created as well.  Here, instead of joining together multiple tables we'll need to extract multiple columns from a single table.\n",
    "\n",
    "\n",
    "Here's the code to fill our date table."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dynamic-alcohol",
   "metadata": {},
   "source": [
    "```SQL\n",
    "INSERT INTO dimDate (date, year, quarter, month, day, week, is_weekend)\n",
    "SELECT DISTINCT(TO_CHAR(create_date, 'yyyyMMDD')::integer) AS id,\n",
    "           create_date AS date,\n",
    "           EXTRACT(year FROM create_date) AS year,\n",
    "           EXTRACT(quarter FROM create_date) AS quarter,\n",
    "           EXTRACT(month FROM create_date) AS month,\n",
    "           EXTRACT(day FROM create_date) AS day,\n",
    "           EXTRACT(week FROM create_date) AS week,\n",
    "           CASE WHEN EXTRACT(ISODOW FROM create_date) IN (6, 7) THEN true ELSE false END AS is_weekend FROM customer;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "injured-actress",
   "metadata": {},
   "source": [
    "The returned code looks like the following."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-lexington",
   "metadata": {},
   "source": [
    "<img src=\"./pagila_select.png\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interesting-cycling",
   "metadata": {},
   "source": [
    "Ok, so let's consider how this code above works.  There are a couple of items that are new.  \n",
    "\n",
    "1. Casting from date to an integer \n",
    "\n",
    "We see this with the following:\n",
    "```SQL\n",
    "SELECT DISTINCT(TO_CHAR(payment_date, 'yyyyMMDD')::integer) AS id\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decreased-dancing",
   "metadata": {},
   "source": [
    "Here, because we cannot directly convert a date to an integer, we first convert our date to a character, with the following: `TO_CHAR(payment_date, 'yyyyMMDD')`, and then we cast *that text* into an integer.  Finally, we only need one date record per unique date, so we wrap this in the `DISTINCT` keyword."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otherwise-transaction",
   "metadata": {},
   "source": [
    "2. Case Statement for Weekend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-preservation",
   "metadata": {},
   "source": [
    "Then, we use a case statement to calculate the is weekend attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprised-ozone",
   "metadata": {},
   "source": [
    "```SQL\n",
    "CASE WHEN EXTRACT(ISODOW FROM create_date) IN (6, 7) THEN true ELSE false END AS is_weekend\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-malaysia",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fiscal-rescue",
   "metadata": {},
   "source": [
    "In this lesson, we saw how we can perform ETL while in SQL.  We do so with the command:\n",
    "\n",
    "```SQL\n",
    "INSERT INTO\n",
    "SELECT\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "familiar-neighbor",
   "metadata": {},
   "source": [
    "Throughout the SELECT statement, we then coerce our data as necessary or join together various tables as necessary. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
